const chunkRepository = require("../repositories/fileChunkRepository");
const fileRepository = require("../repositories/fileRepository");
const cloudinary = require("../config/cloudinary");
const fs = require("fs");
const path = require("path");

// 1Ô∏è‚É£ Kh·ªüi t·∫°o upload (T·∫°o b·∫£n ghi trong database)
const initializeUpload = async ({ filename, mimetype, size }) => {
  const file = await fileRepository.createUploadRecord(
    filename,
    mimetype,
    size
  );
  return file.id; // Tr·∫£ v·ªÅ uploadId ƒë·ªÉ client d√πng ti·∫øp t·ª•c upload
};

// 2Ô∏è‚É£ Upload t·ª´ng chunk
const uploadChunk = async (uploadId, chunkIndex, fileBuffer) => {
  return new Promise((resolve, reject) => {
    try {
      const chunkDir = path.join(__dirname, `../../uploads/chunks/${uploadId}`);
      if (!fs.existsSync(chunkDir)) {
        fs.mkdirSync(chunkDir, { recursive: true });
      }

      const chunkPath = path.join(chunkDir, `chunk_${chunkIndex}`);

      // Ghi buffer tr·ª±c ti·∫øp v√†o file
      fs.writeFileSync(chunkPath, fileBuffer);
      console.log(`‚úÖ Chunk ${chunkIndex} uploaded successfully`);

      resolve({
        message: "Chunk uploaded",
        chunkIndex,
      });
    } catch (error) {
      console.error("‚ùå Error saving chunk:", error);
      reject(new Error(`Error saving chunk: ${error.message}`));
    }
  });
};

// 3Ô∏è‚É£ Ki·ªÉm tra c√°c chunk ƒë√£ upload
const checkUploadedChunks = async (uploadId) => {
  const file = await fileRepository.getFileById(uploadId);
  if (!file) {
    throw new Error("Kh√¥ng t√¨m th·∫•y file");
  }

  const uploadedChunks = await chunkRepository.getUploadedChunks(uploadId);
  const totalChunks = Math.ceil(file.size / 10_000_000); // Gi·∫£ s·ª≠ chunkSize = 10MB

  return { uploadedChunks, totalChunks };
};

// 4Ô∏è‚É£ H·ª£p nh·∫•t chunk v√† upload l√™n Cloudinary
const mergeChunksAndUpload = async (uploadId) => {
  return new Promise(async (resolve, reject) => {
    try {
      const file = await fileRepository.getFileById(uploadId);
      if (!file) {
        return reject(new Error("Kh√¥ng t√¨m th·∫•y file trong database!"));
      }
      
      const chunkDir = path.join(__dirname, `../../uploads/chunks/${uploadId}`);
      const outputFilePath = path.join(
        __dirname,
        `../../uploads/${uploadId}.mp4`
      );

      const chunkFiles = fs
        .readdirSync(chunkDir)
        .filter((file) => file.startsWith("chunk_"))
        .map((file) => ({
          path: path.join(chunkDir, file),
          index: parseInt(file.match(/chunk_(\d+)\.mp4$/)?.[1] || "0"),
        }))
        .sort((a, b) => a.index - b.index);

      if (chunkFiles.length === 0) {
        return reject(new Error("Kh√¥ng t√¨m th·∫•y chunk n√†o ƒë·ªÉ merge!"));
      }

      // T·∫°o file ƒë√≠ch ƒë·ªÉ merge
      const outputStream = fs.createWriteStream(outputFilePath, { flags: "a" });

      // ƒê·ªçc t·ª´ng chunk theo th·ª© t·ª± v√† ghi v√†o file ƒë√≠ch
      chunkFiles.forEach(({ path }) => {
        const chunkBuffer = fs.readFileSync(path);
        outputStream.write(chunkBuffer);
      });

      outputStream.end(() => {
        console.log("‚úÖ Merge ho√†n t·∫•t! Uploading to Cloudinary...");

        // Upload l√™n Cloudinary
        cloudinary.uploader.upload_large(
          outputFilePath,
          {
            resource_type: file.mimetype.startsWith("video/")
              ? "video"
              : "image", // X√°c ƒë·ªãnh lo·∫°i file
            folder: "uploads",
            chunk_size: file.mimetype.startsWith("video/")
              ? 6000000
              : undefined, // Ch·ªâ chunk n·∫øu l√† video
            timeout: 120000,
          },
          async (cloudError, result) => {
            if (cloudError) {
              console.error("‚ùå L·ªói upload Cloudinary:", cloudError);
              return reject(new Error(`Upload error: ${cloudError.message}`));
            }
            // C·∫≠p nh·∫≠t URL v√†o database
            try {
              await fileRepository.markUploadComplete(
                uploadId,
                result.secure_url
              );
              console.log("üìå ƒê√£ l∆∞u URL v√†o database:", result.secure_url);
            } catch (dbError) {
              console.error("‚ùå L·ªói c·∫≠p nh·∫≠t database:", dbError);
            }
            console.log("‚úÖ Upload th√†nh c√¥ng:", result.secure_url);
            resolve(result.secure_url);

            // Cleanup
            try {
              fs.unlinkSync(outputFilePath);
              fs.rmSync(chunkDir, { recursive: true, force: true });
            } catch (cleanupError) {
              console.error("‚ö†Ô∏è L·ªói x√≥a file sau upload:", cleanupError);
            }
          }
        );
      });
    } catch (error) {
      console.error("‚ùå L·ªói merge/upload:", error);
      reject(new Error(`L·ªói khi merge ho·∫∑c upload: ${error.message}`));
    }
  });
};

module.exports = {
  initializeUpload,
  uploadChunk,
  checkUploadedChunks,
  mergeChunksAndUpload,
};
